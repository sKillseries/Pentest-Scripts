#!/bin/bash

url=$1
fqdn=$(echo $url | sed 's#^https://www\.\(.*\)/$#\1#')

if [ ! -d "resultats" ];then
    mkdir resultats
fi
if [ ! -d "resultats/webrecon.txt" ];then
    touch resultats/webrecon.txt
fi
if [ ! -f "resultats/webalive.txt" ];then
    touch resultats/webalive.txt
fi
if [ ! -f "resultats/webfinal.txt" ];then
    touch resultats/webfinal.txt
fi
if [ ! -f "resultats/webassets" ];then
    touch resultats/webassets.txt
fi
if [ ! -f "resultats/web_potential_takeovers.txt" ];then
    touch resultats/web_potential_takeovers.txt
fi
if [ ! -f "resultats/wayback_output.txt" ];then
    touch resultats/wayback_output.txt
fi
if [ ! -f "resultats/web_wayback_output.txt" ];then
    touch resultats/web_wayback_output.txt
fi
if [ ! -f "resultats/web_wayback_params.txt" ];then
    touch resultats/web_wayback_params.txt
fi

echo "[+] HTTP response headers checking..."
echo "[#] Curl Result" >> resultats/webrecon.txt
curl --location --head "$url" >> resultats/webrecon.txt

echo "[+] Site crawling..."
echo "[#] hakrawler Result" >> resultats/webrecon.txt
echo "$url" | hakrawler -d 10 >> resultats/webrecon.txt

echo "[+] Harvesting subdomains with assetfinder..."
assetfinder "$fqdn" >> resultats/webassets.txt
sort -u resultats/webassets.txt >> resultats/webfinal.txt
rm resultats/webassets.txt
 
echo "[+] Double checking for subdomains with amass..."
amass enum -d "$fqdn" >> resultats/webf.txt
sort -u resultats/webf.txt >> resultats/webfinal.txt
rm resultats/webf.txt

echo "[+] dnsrecon enumeration and zone transfer..."
echo "[#] dnsrecon result" >> resultats/webrecon.txt
dnsrecon -a -d "$url" >> resultats/webrecon.txt

echo "[+] Probing for alive domains..."
sort -u resultats/webfinal.txt | httprobe -s -p https:443 | sed 's/https\?:\/\///' | tr -d ':443' >> resultats/weba.txt
sort -u resultats/weba.txt >> resultats/webalive.txt
rm resultats/weba.txt
rm resulats/webfinal.txt
 
echo "[+] Checking for possible subdomain takeover..." 
subjack -w resultats/webalive.txt -t 100 -timeout 30 -ssl -c ~/go/src/github.com/haccer/subjack/fingerprints.json -v 3 -o resultats/web_potential_takeovers.txt
 
echo "[+] Scanning for open ports..."
nmap -iL resultats/webalive.txt -T4 -oA resultats/webscanned
echo "[#] nmap web alive result" >> resultats/webrecon.txt
cat resultats/webscanned.nmap >> resultats/webrecon.txt
rm resultats/webscanned.xml
rm resultats/webscanned.gnmap
rm resultats/webscanned.nmap

echo "[+] Scraping wayback data..."
cat resultats/webalive.txt | waybackurls >> resultats/wayback_output.txt
sort -u resultats/wayback_output.txt >> resultats/web_wayback_output.txt
rm resultats/wayback_output.txt
 
echo "[+] Pulling and compiling all possible params found in wayback data..."
grep '?*=' resultats/web_wayback_output.txt | cut -d '=' -f 1 | sort -u >> resultats/web_wayback_params.txt
for line in $(cat resultats/web_wayback_params.txt);do echo "$line"'=';done
 
echo "[+] Pulling and compiling js/php/aspx/jsp/json files from wayback output..."
for line in $(cat resultats/web_wayback_output.txt);do
    ext="${line##*.}"
    if [[ "$ext" == "js" ]]; then
        echo "$line" >> resultats/web_js.txt
        echo "[#] Wayback scrapping js file result" >> resultats/webrecon.txt
        sort -u resultats/web_js.txt >> resultats/webrecon.txt
    fi
    if [[ "$ext" == "html" ]];then
        echo "$line" >> resultats/web_jsp.txt
        echo "[#] Wayback scrapping jsp file result" >> resultats/webrecon.txt
        sort -u resultats/web_jsp.txt >> resultats/webrecon.txt
    fi
    if [[ "$ext" == "json" ]];then
        echo "$line" >> resultats/web_json.txt
        echo "[#] Wayback scrapping json file result" >> resultats/webrecon.txt
        sort -u resultats/web_json.txt >> resultats/webrecon.txt
    fi
    if [[ "$ext" == "php" ]];then
        echo "$line" >> resultats/web_php.txt
        echo "[#] Wayback scrapping php file result" >> resultats/webrecon.txt
        sort -u resultats/web_php.txt >> resultats/webrecon.txt
    fi
    if [[ "$ext" == "aspx" ]];then
        echo "$line" >> resultats/web_aspx.txt
        echo "[#] Wayback scrapping aspx file result" >> resultats/webrecon.txt
        sort -u resultats/web_aspx.txt >> resultats/webrecon.txt
    fi
done
 
rm resultats/web_js.txt
rm resultats/web_jsp.txt
rm resultats/web_json.txt
rm resultats/web_php.txt
rm resultats/web_aspx.txt

echo "[+] Running eyewitness against all compiled domains..."
eyewitness --web -f resultats/webalive.txt -d resultats/eyewitness --resolve

echo "[+] WAF checking..."
echo "[#] Wafw00f result" >> resultats/webrecon.txt
wafw00f "$url" >> resultats/webrecon.txt

echo "[+] Double WAF checking..."
echo "[#] Whatwaf result" >> resultats/webrecon.txt
whatwaf -u "$url" >> resultats/webrecon.txt

echo "[+] CMS identification checking..."
echo "[#] droopescan result" >> resultats/webrecon.txt
droopescan scan -u "$url" >> resultats/webrecon.txt

rm webalive.txt